ElasticSearch Log

${sys:es.logs.base_path}        日志文件目录
${sys:es.logs.cluster_name}     集群的名称
${sys:es.logs.node_name}        节点的名称

    if log directory (log.path) in elasticsearch.yml is /var/log/elasticsearch and  cluster_name is work
        then  ${sys:es.logs.base_path}= /var/log/elasticsearch
        
appender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_server.json
    =/var/log/elasticsearch/${cluster_name}_server.json
    
appender.rolling.layout.type = ESJsonLayout 
日志的输出格式为json格式
appender.rolling.filePattern 日志滚动的模式名称 可以给文件添加一个后缀 .gz|.zip 这样就可以使用压缩
appender.rolling.policies.time.type = TimeBasedTriggeringPolicy
基于时间的滚动策略
appender.rolling.policies.time.interval = 1
一天滚动一次
appender.rolling.policies.time.modulate = true 
滚动的时间单位为天, 此处为1天一次滚动
appender.rolling.policies.size.type = SizeBasedTriggeringPolicy 
基于大小的滚动策略
appender.rolling.policies.size.size = 256MB 
每256M滚动一次
appender.rolling.strategy.action.type = Delete 
滚动日志时使用删除操作

如果我们需要过渡一段时间后删除文件，我们可以这样
    appender.rolling.strategy.type = DefaultRolloverStrategy 
    追加滚动策略类型
    appender.rolling.strategy.action.type = Delete 
    配置删除操作作为过渡策略
    appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path} 
    设置日志文件路径
    appender.rolling.strategy.action.condition.type = IfFileName 
    
    appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* 
    匹配glob模式的文件, 仅删除已经滚动的日志，而不会删除弃用和满日志
    appender.rolling.strategy.action.condition.nested_condition.type = IfLastModifie    嵌套条件的glob
    appender.rolling.strategy.action.condition.nested_condition.age = 7D 
    日志保留7天
    
配置日志的级别
1. 通过命令行: -E logger.org.elasticsearch.transport=trace           # -E < name of logging hierarchy > = < level >
2. 通过配置文件: logger.org.elasticsearch.transport: debug
3. curl -XPUT /_cluster/settings   -H 'Content-Type: application/json  -d '
         {
           "transient": {
             "<name of logging hierarchy>": "<level>"
           }
         }
4. Via the log4j.properties:
        logger.<unique_identifier>.name = <name of logging hierarchy>
        logger.<unique_identifier>.level = <level>
        
        logger.transport.name = org.elasticsearch.transport
        logger.transport.level = trace
        
Description logging     记录elasticsearch不赞成使用的命令的记录的日志
    logger.description.level = warn
这将会在log dir中创建一个每天滚动的description log.
The default logging configuration has set the roll policy for the description logs to roll and compress after 1GB,
and to preserve a maximum of 5 log files.

    logger.description.name = #####
    logger.description.level = error 如果设置为error, 则会禁用此政策.

The user ID is included in the X-Opaque-ID field in description JSON logs.
        {
          "type": "deprecation",
          "timestamp": "2019-08-30T12:07:07,126+02:00",
          "level": "WARN",
          "component": "o.e.d.r.a.a.i.RestCreateIndexAction",
          "cluster.name": "distribution_run",
          "node.name": "node-0",
          "message": "[types removal] Using include_type_name in create index requests is deprecated. The parameter will be removed in the next major version.",
          "x-opaque-id": "MY_USER_ID",
          "cluster.uuid": "Aq-c-PAeQiK3tfBYtig9Bw",
          "node.id": "D7fUYfnfTLa2D7y-xw6tZg"
        }

我们可以使用Json格式的日志格式来使日志表现的简单易懂
appender.rolling.layout.type = ESJsonLayout
